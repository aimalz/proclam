\section{Conclusion}
\label{sec:conclusion}

We have presented an investigative approach to selecting an appropriate metric of the performance of classification techniques producing class posterior probabilities in the context of \plasticc.
We conclude that the Brier score and log-loss metrics could both be appropriate metrics for \plasticc\ on the basis of their responses to the most concerning systematics anticipated of competing classifiers.
Even though the Brier score and log-loss metrics take values consistent with one another, they are structurally and conceptually different, with wholly different interpretations.
The Brier score is a sum of square differences between probabilities, which is not physically meaningful, though the explicit penalty term is an attractive feature.
The log-loss, on the other hand, is interpretable in terms of information, meaning the metric itself can serve as a quantification of uncertainty to be propagated through forecasting of the constraining power of \lsst\ data.

Both require an additional mechanism, such as weighted averaging between classes to prevent domination by a classifier that focuses exclusively on the most prevalent class, thereby failing to meet \plasticc's diverse goals.
We choose the weighted log-loss for the overall \plasticc\ metric less because it is more sensitive to our concerning systematics and more because it is interpretable, with weights to be chosen on the basis of scientific merit.
We conclude by encouraging the astronomical community to continue to pursue open challenges but to think carefully about the relationship between the goals of a challenge and the global performance metric, as we have done for \plasticc, to ensure that efforts are best directed to achieve the challenge objectives.
