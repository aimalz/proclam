\section{Conclusion}
\label{sec:conclusion}

We have presented the investigative approach to selecting an appropriate metric of the performance of classification techniques producing class posterior probabilities in the context of \plasticc.
We conclude that the Brier score and log-loss metrics could both be appropriate metrics for \plasticc\ on the basis of their responses to the most concerning systematics anticipated of competing classifiers, however, the log-loss is more sensitive to all the systematics we tested.
Both require an additional mechanism, such as weighted averaging between classes to prevent domination by a classifier that focuses exclusively on the most prevalent class, thereby failing to meet \plasticc's diverse goals.

Even though the Brier score and log-loss metrics take values consistent with one another, they are structurally and conceptually different, with wholly different interpretations.
The Brier score is a sum of square differences between probabilities, which is not physically meaningful, though the explicit penalty term is an attractive feature.
The log-loss, on the other hand, is interpretable in terms of information, meaning the metric itself can serve as a quantification of uncertainty to be propagated through forecasting of the constraining power of \lsst\ data.
We therefore choose the weighted log-loss for the overall \plasticc\ metric, with weights to be chosen on the basis of scientific merit.

We conclude by encouraging the astronomical community to continue to pursue open challenges but to think carefully about the relationship between the goals of a challenge and the global performance metric, as we have done for \plasticc, to ensure that efforts are best directed to achieve the challenge objectives.
